{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10796074,"sourceType":"datasetVersion","datasetId":6700286},{"sourceId":6169,"sourceType":"modelInstanceVersion","modelInstanceId":4703,"modelId":2828}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"]=\"tensorflow\"\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\nos.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:05.666532Z","iopub.execute_input":"2025-04-03T14:42:05.666720Z","iopub.status.idle":"2025-04-03T14:42:05.670754Z","shell.execute_reply.started":"2025-04-03T14:42:05.666702Z","shell.execute_reply":"2025-04-03T14:42:05.669719Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import requests\n\nurl=\"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\"\nresponse=requests.get(url)\n\nif response.status_code==200:\n    with open(\"index.xml\",\"w\",encoding=\"utf-8\") as file:\n        file.write(response.text)\n    print(\"Download successful: index.xml saved.\")\nelse:\n    print(f\"Failed to download. HTTP Status Code: {response.status_code}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:21.486311Z","iopub.execute_input":"2025-04-03T14:42:21.486591Z","iopub.status.idle":"2025-04-03T14:42:21.833264Z","shell.execute_reply.started":"2025-04-03T14:42:21.486570Z","shell.execute_reply":"2025-04-03T14:42:21.832506Z"}},"outputs":[{"name":"stdout","text":"Download successful: index.xml saved.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import gc\nimport tensorflow as tf\ngc.collect()\ntf.keras.backend.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:23.062725Z","iopub.execute_input":"2025-04-03T14:42:23.063010Z","iopub.status.idle":"2025-04-03T14:42:35.225580Z","shell.execute_reply.started":"2025-04-03T14:42:23.062986Z","shell.execute_reply":"2025-04-03T14:42:35.224632Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.mixed_precision import Policy,set_global_policy\ntf.config.optimizer.set_jit(True)\npolicy=Policy('mixed_float16')\nset_global_policy(policy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:38.687911Z","iopub.execute_input":"2025-04-03T14:42:38.688523Z","iopub.status.idle":"2025-04-03T14:42:38.701955Z","shell.execute_reply.started":"2025-04-03T14:42:38.688493Z","shell.execute_reply":"2025-04-03T14:42:38.701322Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nimport nltk\nimport zipfile\n\nwordnet_path = \"/usr/share/nltk_data/corpora/wordnet.zip\"\nwordnet_dir = \"/usr/share/nltk_data/corpora/wordnet\"\n\n# Unzipping the WordNet data to the target directory\nif not os.path.exists(wordnet_dir):\n    with zipfile.ZipFile(wordnet_path, 'r') as z:\n        z.extractall(\"/usr/share/nltk_data/corpora/\")\n\nnltk.data.path.append(\"/usr/share/nltk_data/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:40.387709Z","iopub.execute_input":"2025-04-03T14:42:40.388008Z","iopub.status.idle":"2025-04-03T14:42:41.464806Z","shell.execute_reply.started":"2025-04-03T14:42:40.387983Z","shell.execute_reply":"2025-04-03T14:42:41.464117Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndata=pd.read_csv(\"/kaggle/input/tiktoken-happydb/cleaned_hm.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:42.861189Z","iopub.execute_input":"2025-04-03T14:42:42.861738Z","iopub.status.idle":"2025-04-03T14:42:43.433177Z","shell.execute_reply.started":"2025-04-03T14:42:42.861710Z","shell.execute_reply":"2025-04-03T14:42:43.432398Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport pandas as pd\nimport re\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('omw-1.4')\nnltk.download('wordnet')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_text(text):\n    text = re.sub(r'<.*?>', '', text)\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return ' '.join(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:44.643267Z","iopub.execute_input":"2025-04-03T14:42:44.643549Z","iopub.status.idle":"2025-04-03T14:42:44.855010Z","shell.execute_reply.started":"2025-04-03T14:42:44.643528Z","shell.execute_reply":"2025-04-03T14:42:44.854314Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"data['cleaned_hm']=data['cleaned_hm'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:42:47.446641Z","iopub.execute_input":"2025-04-03T14:42:47.446956Z","iopub.status.idle":"2025-04-03T14:43:03.065777Z","shell.execute_reply.started":"2025-04-03T14:42:47.446932Z","shell.execute_reply":"2025-04-03T14:43:03.065037Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nreflection_encoder = LabelEncoder()\ndata['reflection_period_encoded'] = reflection_encoder.fit_transform(data['reflection_period'])\n\ncategory_encoder = LabelEncoder()\ndata['ground_truth_category_encoded'] = category_encoder.fit_transform(data['ground_truth_category'])\ndata['predicted_category_encoded'] = category_encoder.fit_transform(data['predicted_category'])\n\nencoded_columns = {\n    \"reflection_period_encoded\": data['reflection_period_encoded'].unique(),\n    \"ground_truth_category_encoded\": data['ground_truth_category_encoded'].unique(),\n    \"predicted_category_encoded\": data['predicted_category_encoded'].unique(),\n}\nencoded_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:07.893189Z","iopub.execute_input":"2025-04-03T14:43:07.893635Z","iopub.status.idle":"2025-04-03T14:43:07.968561Z","shell.execute_reply.started":"2025-04-03T14:43:07.893598Z","shell.execute_reply":"2025-04-03T14:43:07.967871Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'reflection_period_encoded': array([0, 1]),\n 'ground_truth_category_encoded': array([7, 2, 5, 1, 3, 0, 6, 4]),\n 'predicted_category_encoded': array([1, 4, 2, 5, 0, 3, 6])}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data['cleaned_hm']  \ny = data['predicted_category']\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=42,stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:09.172613Z","iopub.execute_input":"2025-04-03T14:43:09.172965Z","iopub.status.idle":"2025-04-03T14:43:09.278917Z","shell.execute_reply.started":"2025-04-03T14:43:09.172938Z","shell.execute_reply":"2025-04-03T14:43:09.278029Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42,stratify=y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:09.921715Z","iopub.execute_input":"2025-04-03T14:43:09.922012Z","iopub.status.idle":"2025-04-03T14:43:10.000821Z","shell.execute_reply.started":"2025-04-03T14:43:09.921991Z","shell.execute_reply":"2025-04-03T14:43:10.000110Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import RobertaTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:10.904253Z","iopub.execute_input":"2025-04-03T14:43:10.904542Z","iopub.status.idle":"2025-04-03T14:43:15.463310Z","shell.execute_reply.started":"2025-04-03T14:43:10.904520Z","shell.execute_reply":"2025-04-03T14:43:15.462642Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:17.718339Z","iopub.execute_input":"2025-04-03T14:43:17.718941Z","iopub.status.idle":"2025-04-03T14:43:24.115199Z","shell.execute_reply.started":"2025-04-03T14:43:17.718910Z","shell.execute_reply":"2025-04-03T14:43:24.114435Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d335e30f97a5421c9f143ed136a103e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe9089b1a1f40dea3b687852e776836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8916dde8d437499db920c5c0756206c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7028fa33e39a4b03a5cd13f2f6e7c912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69c6e6e0c3d844d9b34162376fc663e6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=128)\ntest_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:25.258079Z","iopub.execute_input":"2025-04-03T14:43:25.258740Z","iopub.status.idle":"2025-04-03T14:43:40.982520Z","shell.execute_reply.started":"2025-04-03T14:43:25.258709Z","shell.execute_reply":"2025-04-03T14:43:40.981834Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\ny_val_encoded = label_encoder.transform(y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:42.872019Z","iopub.execute_input":"2025-04-03T14:43:42.872374Z","iopub.status.idle":"2025-04-03T14:43:42.893787Z","shell.execute_reply.started":"2025-04-03T14:43:42.872348Z","shell.execute_reply":"2025-04-03T14:43:42.893088Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"batch_size=16\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    {\"input_ids\": train_encodings[\"input_ids\"],\"attention_mask\": train_encodings[\"attention_mask\"]}, \n    y_train_encoded\n)).batch(batch_size)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    {\"input_ids\": val_encodings[\"input_ids\"],\"attention_mask\": val_encodings[\"attention_mask\"]}, \n    y_val_encoded\n)).batch(batch_size)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    {\"input_ids\": test_encodings[\"input_ids\"],\"attention_mask\": test_encodings[\"attention_mask\"]}, \n    y_test_encoded\n)).batch(batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:43:43.608636Z","iopub.execute_input":"2025-04-03T14:43:43.608962Z","iopub.status.idle":"2025-04-03T14:44:21.470624Z","shell.execute_reply.started":"2025-04-03T14:43:43.608933Z","shell.execute_reply":"2025-04-03T14:44:21.469917Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from transformers import RobertaTokenizer,TFRobertaForSequenceClassification\nnum_classes = 7\nmodel = TFRobertaForSequenceClassification.from_pretrained(\n    \"roberta-base\", num_labels=num_classes\n)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:44:41.796382Z","iopub.execute_input":"2025-04-03T14:44:41.796692Z","iopub.status.idle":"2025-04-03T14:44:46.062574Z","shell.execute_reply.started":"2025-04-03T14:44:41.796667Z","shell.execute_reply":"2025-04-03T14:44:46.061742Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2b6bbcea196477882b7cc2ef73c614f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_roberta_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n roberta (TFRobertaMainLaye  multiple                  124055040 \n r)                                                              \n                                                                 \n classifier (TFRobertaClass  multiple                  595975    \n ificationHead)                                                  \n                                                                 \n=================================================================\nTotal params: 124651015 (475.51 MB)\nTrainable params: 124651015 (475.51 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from transformers import AdamWeightDecay\noptimizer=AdamWeightDecay(learning_rate=5e-5,weight_decay_rate=0.01)\nmodel.compile(optimizer=optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"],jit_compile=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:44:49.871481Z","iopub.execute_input":"2025-04-03T14:44:49.871825Z","iopub.status.idle":"2025-04-03T14:44:49.892631Z","shell.execute_reply.started":"2025-04-03T14:44:49.871797Z","shell.execute_reply":"2025-04-03T14:44:49.891696Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"best_val_loss=float('inf')\npatience_counter=0\n\nfor epoch in range(5):\n    print(f\"\\nEpoch {epoch + 1}/{5}\")\n    model.fit(train_dataset, epochs=1)\n    \n    val_loss,val_accuracy = model.evaluate(val_dataset)  \n    \n    if val_loss < best_val_loss:  \n        best_val_loss = val_loss\n        model.save_weights(\"best_model_weights.h5\")\n        patience_counter = 0\n    else:\n        patience_counter += 1\n\n    if patience_counter >= 5:\n        print(\"\\nEarly stopping triggered.\")\n        break\n\nmodel.load_weights(\"best_model_weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:44:51.486938Z","iopub.execute_input":"2025-04-03T14:44:51.487275Z","iopub.status.idle":"2025-04-03T16:08:02.389384Z","shell.execute_reply.started":"2025-04-03T14:44:51.487247Z","shell.execute_reply":"2025-04-03T16:08:02.388448Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\nWARNING: AutoGraph could not transform <function infer_framework at 0x7d9ecc681360> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n4242/4242 [==============================] - 1020s 230ms/step - loss: 0.4829 - accuracy: 0.8328\n472/472 [==============================] - 44s 70ms/step - loss: 0.3915 - accuracy: 0.8643\n\nEpoch 2/5\n4242/4242 [==============================] - 954s 225ms/step - loss: 0.3531 - accuracy: 0.8746\n472/472 [==============================] - 28s 59ms/step - loss: 0.3591 - accuracy: 0.8779\n\nEpoch 3/5\n4242/4242 [==============================] - 954s 225ms/step - loss: 0.2785 - accuracy: 0.9020\n472/472 [==============================] - 28s 59ms/step - loss: 0.3709 - accuracy: 0.8805\n\nEpoch 4/5\n4242/4242 [==============================] - 953s 225ms/step - loss: 0.2215 - accuracy: 0.9234\n472/472 [==============================] - 28s 58ms/step - loss: 0.3881 - accuracy: 0.8814\n\nEpoch 5/5\n4242/4242 [==============================] - 953s 225ms/step - loss: 0.1758 - accuracy: 0.9401\n472/472 [==============================] - 28s 58ms/step - loss: 0.4469 - accuracy: 0.8771\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"results=model.evaluate(test_dataset)\nprint(\"Test Loss:\",results[0])\nprint(\"Test Accuracy:\",results[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:08:12.047520Z","iopub.execute_input":"2025-04-03T16:08:12.047820Z","iopub.status.idle":"2025-04-03T16:09:50.164116Z","shell.execute_reply.started":"2025-04-03T16:08:12.047796Z","shell.execute_reply":"2025-04-03T16:09:50.163247Z"}},"outputs":[{"name":"stdout","text":"1571/1571 [==============================] - 98s 62ms/step - loss: 0.3612 - accuracy: 0.8754\nTest Loss: 0.3611977994441986\nTest Accuracy: 0.8753879070281982\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"results1=model.evaluate(val_dataset)\nprint(\"Train Loss:\",results1[0])\nprint(\"Train Accuracy:\",results1[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:10:08.680119Z","iopub.execute_input":"2025-04-03T16:10:08.680432Z","iopub.status.idle":"2025-04-03T16:10:36.324592Z","shell.execute_reply.started":"2025-04-03T16:10:08.680408Z","shell.execute_reply":"2025-04-03T16:10:36.323770Z"}},"outputs":[{"name":"stdout","text":"472/472 [==============================] - 28s 59ms/step - loss: 0.3591 - accuracy: 0.8779\nTrain Loss: 0.3590981364250183\nTrain Accuracy: 0.8778676390647888\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred_logits=model.predict(test_dataset)[\"logits\"]\ny_pred_classes=np.argmax(y_pred_logits,axis=1)\nprint(classification_report(y_test_encoded,y_pred_classes,target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:10:58.248816Z","iopub.execute_input":"2025-04-03T16:10:58.249190Z","iopub.status.idle":"2025-04-03T16:12:42.851330Z","shell.execute_reply.started":"2025-04-03T16:10:58.249159Z","shell.execute_reply":"2025-04-03T16:12:42.850514Z"}},"outputs":[{"name":"stdout","text":"1571/1571 [==============================] - 104s 60ms/step\n                  precision    recall  f1-score   support\n\n     achievement       0.88      0.88      0.88      8498\n       affection       0.95      0.93      0.94      8542\n         bonding       0.91      0.94      0.92      2682\nenjoy_the_moment       0.70      0.75      0.73      2786\n        exercise       0.71      0.91      0.80       300\n         leisure       0.80      0.73      0.77      1865\n          nature       0.70      0.80      0.75       461\n\n        accuracy                           0.88     25134\n       macro avg       0.81      0.85      0.83     25134\n    weighted avg       0.88      0.88      0.88     25134\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n\naccuracy=accuracy_score(y_test_encoded,y_pred_classes)\nprecision=precision_score(y_test_encoded,y_pred_classes,average='weighted')\nrecall=recall_score(y_test_encoded,y_pred_classes,average='weighted')\nf1=f1_score(y_test_encoded,y_pred_classes,average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision : {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T16:12:54.057063Z","iopub.execute_input":"2025-04-03T16:12:54.057438Z","iopub.status.idle":"2025-04-03T16:12:54.092435Z","shell.execute_reply.started":"2025-04-03T16:12:54.057409Z","shell.execute_reply":"2025-04-03T16:12:54.091490Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8754\nPrecision : 0.8777\nRecall: 0.8754\nF1 Score: 0.8760\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}